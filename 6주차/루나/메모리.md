## 메모리 계층 구조

**`메모리 계층구조`**는 메모리 관련 세 가지 주요 특성인 **용량**, **접근속도**, **비용** 간의 절충 관계를 파악해 필요에 따라 채택할 수 있게 나타낸 구조이다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/acf0799b-2665-497c-a790-b8d7ec12b4c4/Untitled.png)

계층구조 아래쪽으로 내려갈수록 다음 내용이 성립한다.

- 비트당 비용 감소
- 용량 증가
- 접근 시간 증가 (속도 느림)
- 처리기에 의한 메모리 접근 회수 감소

### **메모리 계층구조의 필요성**

**`자주 쓰이는 데이터는 반복해서 쓰인다 = 참조 지역성(locality of reference)`**

프로그램은 일반적으로 많은 반복 루프와 서브루틴을 포함하고 있다. 일단 루프나 서브루틴으로 진입하면, 적은 수의 명령어 집단들이 반복해서 참조된다.

따라서 자주 쓰일 것 같은 데이터는 메모리에서 캐시로 읽어와서, 메모리까지 가지 않고 한동안 캐시에서 해결이 가능하므로 시간을 단축시킬 수 있다.

전체 프로그램 중 일부 데이터를 집중 사용하는 것이기에 메모리 용량이 작아도 된다.

## 메인메모리

> 메인 메모리는 CPU가 직접 접근할 수 있는 기억 장치
>
>
> 프로세스가 실행되려면 프로그램이 메모리에 올라와야 함
>

- 주소가 할당된 일련의 바이트들로 구성되어 있음
- CPU는 레지스터가 지시하는대로 메모리에 접근하여 다음에 수행할 명령어를 가져옴
- **MMU** : 명령어 수행 시 메모리에 필요한 데이터가 없으면 해당 데이터를 우선 가져오는 역할을 함.

### 주소 바인딩 (Address binding)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e8952a62-797b-4e22-ac3e-e9b119d10aff/Untitled.png)

프로그래밍에서 변수를 선언하면 컴파일러가 변수를 메모리에 올리기 때문에 정확한 주소가 무엇인지 알 수 없는 것처럼, 프로그램은 실행되기 전까지 단지 디스크에 저장되어있는 이진 실행파일에 불과함. 실행을 위해 메인
메모리에 올라가는 순간 비로소 **프로세스**가 되는 것.

- 컴파일러는 프로그래머가 작성한 소스 코드 내의 주소를 재배치 가능한 (relocatable) 주소에 바인딩 함
- 링커를 통해 논리적인 주소를 만들고, 로더를 실행할 때 다시금 절대(absolute) 주소에 바인딩 함 (physical한 주소)
- 각 단계마다 다른 주소 바인딩이 이루어진다.

**논리적 주소 공간 vs 물리적 주소 공간**

- **논리 주소 (logical address)**: 사용자 프로세스에서 사용하기 위해 CPU에서 생성된 주소.
- **물리 주소 (physical address)**: 실제 하드웨어 상의 주소. 논리 주소와는 아무런 관계가 없어야 하며, 메모리 주소 레지스터 (memory-address register)에 저장되는 주소.

논리 주소를 물리 주소에 매핑하기 위해서는 **논리적 주소 공간 (logical address space)**와 **물리적 주소 공간 (physical address space)**이 분리되어야 함.

## **MMU (Memory Management Unit, 메모리 관리 장치)**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/da46d5bd-9f21-4962-83f5-aacd2eb520f4/Untitled.png)

- 논리 주소를 물리주소로 변환해 준다.
- 메모리 보호나 캐시 관리 등 CPU가 메모리에 접근하는 것을 총 관리해주는 하드웨어임

메모리의 공간이 한정적이기 때문에, 사용자에게 더 많은 메모리를 제공하기 위해 '가상 주소'라는 개념이 등장 (가상 주소는 프로그램 상에서 사용자가 보는 주소 공간이라고 보면 됨)

이 가상 주소에서 실제 데이터가 담겨 있는 곳에 접근하기 위해선 빠른 주소 변환이 필요한데, 이를 MMU가 도와주는 것

### MMU의 역할

- MMU는 사용자가 기억장소를 일일이 할당해야 하는 불편을 없애준다.
- 프로세스의 크기가 실제 메모리의 용량을 초과해도 실행될 수 있게 해준다.

### MMU의 메모리 보호

프로세스는 **독립적인 메모리 공간**을 가져야 하고, 자신의 공간만 접근해야 한다.따라서 MMU는 한 프로세스에게 합법적인 주소 영역을 설정하고, 잘못된 접근이 오면 trap을 발생시키며 보호한다.

base와 limit 레지스터를 활용한 메모리 보호 기법

- **base 레지스터** : 메모리상의 프로세스 시작주소를 물리 주소로 저장
- **limit** 레지스터 : 프로세스의 사이즈를 저장

프로세스의 접근 가능한 합법적인 메모리 영역(`x`)은 `base <= x < base+limit` 이 된다.따라서 이 영역 밖에서 접근을 요구하면 trap을 발생시킨다.

안전성을 위해 base와 limit 레지스터는 사용자 모드에서는 직접 변경할 수 없도록 커널 모드에서만 수정 가능하도록 설계되었다.

## **캐시 메모리**

- 주기억장치에서 자주 쓰는 프로그램과 데이터를 저장해 속도를 빠르게 하는 메모리
    - 그러므로 캐시는 주기억장치보다 크기가 작을 수밖에 없다!
    - 캐시 기억장치와 주기억장치 사이에서 정보를 옮기는 것을 **사상(Mapping, 매핑)**이라고 함
        - 매핑의 3가지 방법직접 매핑(Direct Mapping), 연관 매핑(Associate Mapping), 집합 연관 매핑(Set Associate Mapping)
- 속도가 빠른 장치와 느린 장치간의 속도 차에 따른 병목현상을 줄이기 위한 범용 메모리
    - 이를 위해서는 CPU가 어떤 데이터를 원하는지 어느 정도 예측할 수 있어야 한다.
    - 캐시 메모리에 CPU가 이후에 참조할, 필요 있는 정보가 어느 정도 들어있느냐에 따라 캐시의 성능이 좌우되기 때문
- 주기억장치와 CPU 사이에 위치한다
- 메모리 계층 구조에서 가장 빠르며, 처리속도가 거의 CPU와 비슷하다
- 캐시 메모리를 사용하면 주 기억장치를 접근하는 횟수가 줄어들어 속도가 향상된다.
- 캐시는 플리플롭 소자로 구성되어 SRAM으로 되어있어서 DRAM보다 빠른 장점을 지님
- CPU가 이미 봤던걸 다시 재접근할 때, 메모리 참조 및 인출 과정에 대한 비용을 줄이기 위해 캐시에 저장해둔 데이터를 활용한다

### **캐시(Cache)의 지역성(Locality)**

- 캐시가 효율적으로 동작하려면, 캐시의 적중율(Hit-rate)를 극대화 시켜야 한다.
- 캐시에 저장할 데이터가 **지역성(Locality)**을 가져야 한다.
- 지역성이란, **데이터 접근이 시간적, 혹은 공간적으로 가깝게 일어나는 것**을 의미한다.
- 지역성의 전제 조건으로 프로그램은 모든 코드나 데이터를 균등하게 Access하지 않는다는 특성을 기본으로 한다.
- 즉, **지역성(Locality)**이란
    - 기억장치 내의 정보를 균일하게 Access하는 것이 아닌 **어느 한 순간에 특정 부분을 집중적으로 참조하는 특성**이다.

**시간적 지역성**

- 특정 데이터가 한번 접근되었을 경우, 가까운 미래에 **또 한번 데이터에 접**근할 가능성이 높은 것
- 메모리 상의 **같은 주소**에 여러 차례 읽기 쓰기를 수행할 경우,
    - 상대적으로 작은 크기의 캐시를 사용해도 효율성을 꾀할 수 있다.

**공간적 지역성**

- 특정 데이터와 **가까운 주소**가 순서대로 접근되었을 경우.
- CPU 캐시나 디스크 캐시의 경우 한 메모리 주소에 접근할 때 그 주소뿐 아니라 해당 블록을 전부 캐시에 가져오게 된다.
- 이때 메모리 주소를 **오름차순이나 내림차순으로 접근**한다면,
    - 캐시에 이미 저장된 같은 블록의 데이터를 접근하게 되므로 캐시의 효율성이 크게 향상된다.

### **캐시 메모리의 매핑 프로세스(Mapping Process)**

**매핑 프로세스는 주기억장치로부터 캐시 메모리로 데이터를 전송하는 방법**으로 3가지 방법이 있다.

- **직접 매핑(direct Mapping)**
    - 주기억장치의 블록들이 지정된 한 개의 캐시 라인으로만 사상될 수 있는 매핑 방법.
    - 간단하고 구현하는 비용이 적게드는 장점이 있지만 적중률이 낮아질 수 있다는 단점이 있다.
- **어소시에이티브 매핑(Associative Mapping)**
    - 직접 매핑 방식의 단점을 보완한 방식.
    - 모든 태그들을 병렬로 검사하기 때문에 복잡하고 비용이 높다는 단점이 있어 거의 사용하지 않는다.
- **세트-어소시에이티브 매핑(Set-Associative Mapping)**
    - 직접 매핑과 연관 매핑의 장점만을 취한 방식.

### **캐싱 라인**

빈번하게 사용되는 데이터들을 캐시에 저장했더라도, 내가 필요한 데이터를 캐시에서 찾을 때 모든 데이터를 순회하는 것은 시간 낭비다.

즉, 캐시에 **목적 데이터가 저장되어있을 때 바로 접근하여 출**력할 수 있어야 캐시 활용이 의미있어짐

따라서 캐시에 데이터를 저장할 때, set이나 map 등의 자료구조를 활용해 **데이터와 데이터의 메모리 주소를 함께 묶어서 저장** 하는데 이를 캐싱 라인이라고 부른다.

### 캐시 vs 레지스터

### 레지스터

> CPU에 존재하는 다목적 저장 공간
>

레지스터는 메모리 계층의 최상위에 위치하며, **가장 빠른 속도로 접근 가능**한 메모리이다.**데이터와 명령어를 저장**하는 역할을 하며 일반적으로 현재 계산을 수행중인 값을 저장하는 데 사용된다.대부분의 현대
프로세서는 **메인 메모리에서 레지스터로 데이터를 옮겨와 데이터를 처리한 후 그 내용을 다시 레지스터에서 메인 메모리로 저장**하는 로드-스토어 설계를 사용하고 있다.

- **공통점**
    - 어떤 명령어나 데이터를 저장해두는 저장 공간이다.
- **차이점**
    - 용도에 따른 차이점이 존재한다.
    - **캐시** : cpu와 별도로 있는 공간이며, 메인 메모리와 cpu 간의 속도 차이를 극복하기 위한 것
    - **레지스터** : cpu 안에서 연산을 처리하기 위하여 데이터를 저장하는 공간 이라는 것